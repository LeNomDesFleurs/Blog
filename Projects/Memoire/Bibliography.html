<!DOCTYPE html>
<lang="en-US">

    <head>
        <title>Le Nom Des Fleurs</title>
        <meta name="author" content="Thomas Guillory" />
        <meta name="Description" content="bibliographie, macro knob mapping" />

        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="/tufte.css" type="text/css">
    </head>

    <body>
        <h1>Bibliography</h1>

        <section>
            <h4>Reading recommendations</h4>
Some “introductory” articles that helped me:
<ul>
<li>Mapping performer parameters to synthesis engines (Hunt, & Wanderley, 2002) gives a good overview of the history of mapping, but is a little dated. </li>
<li>SoundTraveller: Exploring Abstraction and Entanglement in Timbre Creation Interfaces for Synthesizers (Sramek et al. 2023). For a quick introduction to agentivity in the musical context and the place of presets.</li>
<li>Entanglement HCI The Next Wave? (Frauenberger, C. 2019). To go further on the notion of agentivity, offers a historical tour of all the theories.</li>
<li>The Role of Nonlinear Dynamics in Musicians' Interactions with Digital and Acoustic Musical Instruments (Mudd, T., et al. 2019). For thinking about nonlinearity.</li>
<li>A framework for the development and evaluation of graphical interpolation for synthesizer parameter mappings (Gibson, D., & Polfreman, R. 2019). For the history of graphical interpolators.</li>
</ul>

<h4>Bibliography</h4>
            <p>
<ul>
<li>Analog Lab V User Manual (2021) Arturia  <a href=https://dl.arturia.net/products/analoglab-v/manual/AnalogLab-V_Manual_5_3_EN.pdf>pdf / website source</a></li>
<li>Arp 2600 patch book <a href=https://www.korg.com/us/support/download/manual/0/842/4471>pdf / website source</a></li>
<li>Arp instrument Inc. (1976). ARP Odyssey Owner's Manual <a href="http://arpodyssey.com/Arp_Odyssey_Manual.pdf">pdf / website source</a></li>
<li>Bowler, I., Purvis, A., Manning, P.D., & Bailey, N.J. (1990). On Mapping N Articulation Onto M Synthesiser-control Parameters. International Conference on Mathematics and Computing. <a href=https://www.researchgate.net/publication/243775690_On_Mapping_N_Articulation_onto_M_Synthesiser-Control_Parameters>pdf / website source</a></li>
<li>Buxton, W. (1986) There's More to Interaction than Meets the Eye: Some Issues in Manual Input. In Norman, D. A. and Draper, S. W. (Eds.), (1986), User Centered System Design: New Perspectives on Human-Computer Interaction. Lawrence Erlbaum Associates, Hillsdale, New Jersey, 319-337.</li>
<li>Carlos M., Stewart T. (1985). Fairlight CMI Operation manual <a href=https://archive.org/details/JL10273>pdf / website source</a></li>
<li>Chowning J. M. (1977) The Synthesis of Complex Audio Spectra by Means of Frequency Modulation <a href=https://www.jstor.org/stable/23320142>pdf / website source</a></li>
<li>Frauenberger, C. (2019). Entanglement HCI The Next Wave? ACM Transactions on Computer-Human Interaction (TOCHI), 27, 1 - 27. <a href=https://frauenberger.name/research/publications/EntanglementHCI.pdf>pdf / website source</a></li>
<li>Garnet, G. E., & Goudeseune, C. (1999) Performance Factors in Control of High-Dimensional Spaces, ICM Proceedings <a href=https://quod.lib.umich.edu/i/icmc/bbp2372.1999.393/--performance-factors-in-control-of-high-dimensional-space>pdf / website source</a></li>
<li>Gaver, W. (1991). Technology Affordances. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. <a href=https://www.researchgate.net/publication/221518931_Technology_Affordances>pdf / website source</a></li>
<li>Gibson, D., & Polfreman, R. (2019). A framework for the development and evaluation of graphical interpolation for synthesizer parameter mappings. <a href="http://eprints.bournemouth.ac.uk/32726/1/A%20Framework%20for%20the%20Development%20and%20Evaluation%20of%20Graphical%20Interpolation%20for%20Synthesizer%20Parameter%20Mappings%20FINAL%20ver5%20%281%29.pdf">pdf / website source</a></li>
<li>Gibson, D., & Polfreman, R. (2020). Analyzing journeys in sound: usability of graphical interpolators for sound design. Personal and Ubiquitous Computing, 1-14. <a href=https://link.springer.com/content/pdf/10.1007/s00779-020-01398-z.pdf>pdf / website source</a></li>
<li>Gibson, D., & Polfreman, R. (2020). Star Interpolator - A Novel Visualization Paradigm for Graphical Interpolators. New Interfaces for Musical Expression. <a href=https://zenodo.org/records/4813168/files/nime2020_paper10.pdf>pdf / website source</a></li>
<li>Goldman, R. F. (1961). REVIEWS OF RECORDS. The Musical Quarterly, XLVII(1), 133‑134. <a href=https://doi.org/10.1093/mq/xlvii.1.133>pdf / website source</a></li>
<li>Hunt, A., & Kirk, R. (2000). Mapping Strategies for Musical Performance. Trends in Gestural Control of Music. <a href=https://www.researchgate.net/publication/243774325_Mapping_Strategies_for_Musical_Performance>pdf / website source</a></li>
<li>Hunt, A., & Wanderley, M. M. (2002). Mapping performer parameters to synthesis engines. Organised Sound, 7(2), 97–108. doi:10.1017/S1355771802002030</li>
<li>Interaction Design Foundation - IxDF. (2016, June 4). What is Skeuomorphism?. Interaction Design Foundation - IxDF. <a href=https://www.interaction-design.org/literature/topics/skeuomorphism>pdf / website source</a></li>
<li>Kirkegaard, M., Bredholt, M.,& Wanderley, M.(2020). An Intermediate Mapping Layer for Interactive Sequencing. doi : 10.1007/978-3-030-50017-7_33</li>
<li>Komplete Kontrol User Manual (2023) Native Instrument <a href=https://www.native-instruments.com/fileadmin/ni_media/downloads/manuals/komplete_kontrol/Komplete_Kontrol_MK3_Manual_English_17102023.pdf>pdf / website source</a></li>
<li>Larkin, O. (2007). Int.Lib - a Graphical Preset interpolator for Max MSP. International Conference on Mathematics and Computing. <a href=https://quod.lib.umich.edu/i/icmc/bbp2372.2007.057?rgn=main;view=fulltext>pdf / website source</a></li>
<li>Lee, M.A., & Wessel, D. (1992). Connectionist Models for Real-Time Control of Synthesis and Compositional Algorithms. International Conference on Mathematics and Computing. <a href=https://cnmat.berkeley.edu/sites/default/files/attachments/1992_Connectionist-Models-for-Real-Time-Control-of-Synthesis.pdf>pdf / website source</a></li>
<li>Levitin D. J., McAdams S., Adams R. L. (2002). Control parameters for musical instruments: a foundation for new mappings of gesture to sound. Organised Sound, 7, 171-189 doi:10.1017/S135577180200208X</li>
<li>McGregor, J. (2019) Knobs and Nodes: A Study of UI Design in Audio Plugins [Mémoire de Master, Massey University, Wellington, New Zealand]. <a href=https://mro.massey.ac.nz/items/f630372b-5871-4864-b4ab-aefc49e4e1fc>pdf / website source</a></li>
<li>Mudd, T. (2023,) Playing with feedback: Unpredictability, immediacy, and entangled agency in the no-input mixing desk.CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems., 243, ACM, pp. 1-11. <a href=https://doi.org/10.1145/3544548.3580662>pdf / website source</a></li>
<li>Mudd, T., Holland, S., & Mulholland, P. (2019). The Role of Nonlinear Dynamics in Musicians' Interactions with Digital and Acoustic Musical Instruments. Computer Music Journal, 43, 25-40. <a href=https://www.semanticscholar.org/paper/The-Role-of-Nonlinear-Dynamics-in-Musicians-with-Mudd-Holland/922fdab66eefaf1fdecbebe665c42a1dbd3795a4>pdf / website source</a></li>
<li>Nirchio, L. (2018) Les aléas du design ou l'aléatoire dans le processus de création [Mémoire de Master, Université Paris 1]. <a href=https://dumas.ccsd.cnrs.fr/dumas-01877194/document>pdf / website source</a></li>
<li>Norman, D. A. (1988). The psychology of everyday things. Basic Books, New York</li>
<li>Roberts, C., & Wakefield, G. (2016). Live Coding the Digital Audio Workstation. <a href=https://www.nime.org/proceedings/2015/nime2015_310.pdf>pdf / website source</a></li>
<li>Rodger, M., Stapleton, P., Van Walstijn, M., Ortiz, M., & Pardue, L. (2020). What Makes a Good Musical Instrument ? A Matter of Processes, Ecologies and Specificities. NIME, 484‑490. <a href=https://pureadmin.qub.ac.uk/ws/files/215811524/nime2020_paper79.pdf>pdf / website source</a></li>
<li>Rovan, J., Wanderley, M., & Dubnov, S. (1997). Instrumental Gestural Mapping Strategies as Expressivity Determinants in Computer Music Performance. <a href=https://www.researchgate.net/publication/2765549_Instrumental_Gestural_Mapping_Strategies_as_Expressivity_Determinants_in_Computer_Music_Performance>pdf / website source</a></li>
<li>Ryan, J. (1991). Some remarks on musical instrument design at STEIM. Contemporary Music Review, 6, 3-17. <a href=https://www.researchgate.net/publication/243784414_Some_remarks_on_musical_instrument_design_at_STEIM>pdf / website source</a></li>
<li>Serge – Modulisme. (s. d.). Modular Station. Consulté le 19 Mars 2023 sur <a href=https://modular-station.com/modulisme/itatiom/serge/>pdf / website source</a></li>
<li>Smith, J. (2021). The Functions of Continuous Processes in Contemporary Electronic Dance Music. <a href=https://www.researchgate.net/publication/352569487_The_Functions_of_Continuous_Processes_in_Contemporary_Electronic_Dance_Music/citation/download>pdf / website source</a></li>
<li>Spain, M., & Polfreman, R. (2001). Interpolator: a two-dimensional graphical interpolation system for the simultaneous control of digital signal processing parameters. Organised Sound, 6, 147 - 151. <a href=https://www.dmu.ac.uk/documents/technology-documents/research/mtirc/nowalls/mww-spain.pdf>pdf / website source</a></li>
<li>Sramek, Z., Sato, A., Zhou, Z., Hosio, S., & Yatani, K. (2023). SoundTraveller: Exploring Abstraction and Entanglement in Timbre Creation Interfaces for Synthesizers. 95-114. 10.1145/3563657.3596089. <a href=https://iis-lab.org/wp-content/uploads/2023/05/DIS2023.pdf>pdf / website source</a></li>
<li>Tagi, E. (2023, 11 juillet). An Interview with Peter Blasser. Perfect Circuit. consulté le <a href=https://www.perfectcircuit.com/signal/peter-blasser-interview>pdf / website source</a></li>
<li>Vinet, H.,& Delalande, F. (1999) Interface homme-machine et création musicale. Hermes Science Publications.</li>
<li>Wanderley, M. M., Schnell, N., and Rovan, J. B. (1998). Escher – modeling and performing composed instruments in real-time. Proc. of the 1998 IEEE Int. Conf. on Systems, Man and Cybernetics (SMC’98), pp. 1,080–4.</li>
<li>Wessel, D. L. (1979). Timbre Space as a Musical Control Structure. Computer Music Journal, 3(2), 45–52. <a href=https://doi.org/10.2307/3680283>pdf / website source</a></li>
<li>Williams, A. (2015) Technostalgia and the cry of the lonely recordist, Journal on the art of record production, no. 9. <a href=https://www.arpjournal.com/asarpwp/technostalgia-and-the-cry-of-the-lonely-recordist/>pdf / website source</a></li>
</ul>
</p>
</section>
    </body>